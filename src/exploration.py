import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# ========================================
# üîç 1. Exploration et compr√©hension
# ========================================

# A Importation et inspection

# d√©finition des types (optimisation m√©moire)
dtype = {
    "Id": "int32",
    "gaming_interest_score": "float32",
    "insta_design_interest_score": "float32",
    "football_interest_score": "float32",
    "recommended_product": "category",
    "campaign_success": "object",
    "age": "float32",
    "canal_recommande": "category"
}

# charger le CSV (les donn√©es)
df = pd.read_csv("data/result.csv", sep=";", dtype=dtype)

# aper√ßu rapide du dataset
print("\n--- 5 premi√®res lignes ---")
print(df.head())

# infos sur le dataset (types, valeurs manquantes, m√©moire)
print("\n--- Informations dataset ---")
print(df.info())

# M√©moire utilis√©e **avant nettoyage**
memoire_avant = df.memory_usage(deep=True).sum() / 1024**2  # en Mo
print(f"\nM√©moire utilis√©e avant nettoyage : {memoire_avant:.2f} Mo")

# B Nettoyage et mise en forme

# stats descriptives pour les colonnes num√©riques
print("\n--- Statistiques descriptives ---")
print(df.describe())

# Nombre de doublons avant suppression
nb_doublons_avant = df.duplicated().sum()
print(f"\nNombre de doublons avant suppression : {nb_doublons_avant}")

# Afficher les doublons
if nb_doublons_avant > 0:
    print("\n--- Doublons avant suppression ---")
    print(df[df.duplicated(keep=False)])

# Supprimer les doublons
df = df.drop_duplicates()

# V√©rification des valeurs manquantes
print("\n--- Valeurs manquantes par colonne ---")
print(df.isna().sum())

# Suppression des lignes avec valeurs manquantes
df = df.dropna()

# V√©rification des types apr√®s transformation
print("\n--- Types de colonnes apr√®s nettoyage ---")
print(df.dtypes)

# M√©moire utilis√©e apr√®s nettoyage
memoire_apres = df.memory_usage(deep=True).sum() / 1024**2
print(f"\nM√©moire utilis√©e apr√®s nettoyage : {memoire_apres:.2f} Mo")

# Statistiques descriptives finales
print("\n--- Statistiques descriptives finales ---")
print(df.describe())

# V√©rification finale des doublons
nb_doublons_final = df.duplicated().sum()
print(f"\nNombre de doublons apr√®s tout nettoyage : {nb_doublons_final}")

# ========================================
# üïµ 2. D√©tection d‚Äôanomalies
# ========================================

# Colonnes num√©riques √† analyser
numeric_cols = [
    "gaming_interest_score",
    "insta_design_interest_score",
    "football_interest_score",
    "age"
]

# üîπ Nettoyage des colonnes pour √©viter les doublons invisibles
categorical_cols = ["recommended_product", "canal_recommande"]

for col in categorical_cols:
    df[col] = df[col].astype(str).str.strip().str.lower()
    df[col] = df[col].str.replace(r'\s+', ' ', regex=True)
    df[col] = df[col].astype("category")

# Ajout majuscule aux cat√©gorie
for col in categorical_cols:
    df[col] = df[col].str.title()

# Conversion de campaign_success en bool√©en
print("\n--- Valeurs uniques dans campaign_success (avant nettoyage) ---")
print(df["campaign_success"].unique())

# Normalisation
df["campaign_success"] = (df["campaign_success"].astype(str).str.strip().str.lower())

# Conversion en bool√©en
df["campaign_success"] = df["campaign_success"].map({"true": True, "false": False})

print("\n--- Valeurs uniques dans campaign_success (apr√®s nettoyage) ---")
print(df["campaign_success"].unique())

# V√©rifier que les colonnes existent r√©ellement dans le dataset
numeric_cols = [col for col in numeric_cols if col in df.columns]
print("Colonnes utilis√©es pour la d√©tection :", numeric_cols)

# Calcul des Z-scores
z_scores = (df[numeric_cols] - df[numeric_cols].mean()) / df[numeric_cols].std(ddof=0)

# D√©tection des anomalies : valeurs dont |Z-score| > 3
anomaly_z = (z_scores.abs() > 3)
print("\nAnomalies d√©tect√©es (Z-score) :")
print(anomaly_z.sum())

# Visualisation
for col in numeric_cols:
    mean_val = df[col].mean()
    std_val = df[col].std(ddof=0)

    # Cr√©er des masques
    anomalies = anomaly_z[col]
    normal = ~anomalies

    plt.figure(figsize=(10, 4))

    # Points normaux
    plt.scatter(df.index[normal], df[col][normal], color='blue', alpha=0.7, label='Normal')
    # Points anomalies
    plt.scatter(df.index[anomalies], df[col][anomalies], color='red', alpha=0.9, label='Anomalie')

    # Moyenne et bornes ¬±3œÉ
    plt.axhline(mean_val, color='green', linestyle='--', linewidth=1.5, label='Moyenne')
    plt.axhline(mean_val + 3*std_val, color='orange', linestyle='--', linewidth=1.5, label='+3œÉ')
    plt.axhline(mean_val - 3*std_val, color='orange', linestyle='--', linewidth=1.5, label='-3œÉ')

    # Titre et l√©gende
    plt.title(f'D√©tection d\'anomalies pour {col}', fontsize=14)
    plt.xlabel('Index', fontsize=12)
    plt.ylabel(col, fontsize=12)
    plt.legend()
    plt.show()

# Supprimer les anomalies pour analyses futures
df_clean = df[~anomaly_z.any(axis=1)]
print(f"\nNombre de lignes apr√®s suppression des anomalies : {df_clean.shape[0]}")

# ========================================
# üìà 3. ANALYSE STATISTIQUE (KPI)
# ========================================

df_stats = df_clean.copy()

print("\n===== ANALYSE STATISTIQUE =====")

# Taux de r√©ussite global
success_rate = df_stats["campaign_success"].mean()
print(f"\nTaux de r√©ussite global : {success_rate*100:.2f}%")

plt.figure(figsize=(5,5))
plt.bar(["Succ√®s"], [success_rate])
plt.title("Taux de r√©ussite global")
plt.ylabel("Taux")
plt.show()


# Taux de r√©ussite par produit recommand√©
success_by_product = df_stats.groupby("recommended_product")["campaign_success"].mean()

print("\nTaux de r√©ussite par produit :")
print(success_by_product)

success_by_product.plot(kind="bar", figsize=(7,5))
plt.title("Taux de r√©ussite par produit")
plt.ylabel("Taux de r√©ussite")
plt.show()


# Taux de r√©ussite par canal
success_by_channel = df_stats.groupby("canal_recommande")["campaign_success"].mean()

print("\nTaux de r√©ussite par canal :")
print(success_by_channel)

success_by_channel.plot(kind="bar", figsize=(7,5))
plt.title("Taux de r√©ussite par canal")
plt.ylabel("Taux de r√©ussite")
plt.show()


# Taux de r√©ussite par tranche d‚Äô√¢ge
df_stats["age_group"] = pd.cut(
    df_stats["age"],
    bins=[0, 18, 30, 45, 60, 99],
    labels=["<18", "18-30", "30-45", "45-60", "60+"]
)

success_by_age = df_stats.groupby("age_group")["campaign_success"].mean()

print("\nTaux de r√©ussite par tranche d‚Äô√¢ge :")
print(success_by_age)

success_by_age.plot(kind="bar", figsize=(7,5))
plt.title("Taux de r√©ussite par √¢ge")
plt.ylabel("Taux de r√©ussite")
plt.show()


# Corr√©lation entre scores d‚Äôint√©r√™t et r√©ussite
score_cols = [
    "gaming_interest_score",
    "insta_design_interest_score",
    "football_interest_score",
    "age"
]

corr = df_stats[score_cols + ["campaign_success"]].corr()

print("\n===== MATRICE DE CORR√âLATION =====")
print(corr)

plt.figure(figsize=(8,6))
plt.imshow(corr, cmap="coolwarm", interpolation="nearest")
plt.colorbar()
plt.title("Matrice de corr√©lation")
plt.xticks(range(len(corr)), corr.columns, rotation=45)
plt.yticks(range(len(corr)), corr.columns)
plt.show()

# ========================================
# 4. Datatelling et cr√©ation de l‚Äôattaque
# ========================================

